{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 기말과제: 인공지능적 영상 인식 기법 개발 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 과제 개요: Image Classification on CIFAR-10 DB\n",
    "\n",
    "\n",
    "### 과제 목표\n",
    "본 기말 과제에서는 10개 class에 대해 32x32x3 차원의 영상 총 60,000장으로 구성되는 CIFAR-10 DB (https://www.cs.toronto.edu/~kriz/cifar.html)의 분류 성능을 극대화하는 영상 분류 기법을 구현하는 것을 목표로 한다.\n",
    "\n",
    "### 과제 운영 방식\n",
    "학생 개개인의 프로그래밍 실력 및 중점적으로 학습하고 싶은 세부적인 부분에 따라 아래의 두 가지 유형 중 하나를 선택하여 수행한다.\n",
    "* 유형1: classifier를 통일한 상태에서 해당 classifier의 입력으로 들어오는 data feature vector를 생성하는 기법을 자체적으로 구현함. 외부 코드 차용은 원칙적으로 불가하며, 최종적인 판별 결과보다 개발 과정에서 수행한 다양한 시도와 실험을 기준으로 평가함.\n",
    "* 유형2: 모든 외부 코드의 차용을 원칙적으로 허용하되, 활용하는 외부 코드에 대해 line-by-line으로 주석 설명문을 작성하거나 코드를 수정/개선하는 등 스스로 상세하게 이해하여 활용함. 최종적인 판별 결과를 극대화하는 것을 목표로 하며 최종 정확도를 기준으로 평가함.\n",
    "\n",
    "이때 유형 1, 유형 2 모두 아래의 기본적인 외부 패키지는 활용이 허용된다.\n",
    "* Numpy\n",
    "* Pandas\n",
    "* Scikit-image (skimage.feature module은 사용 불가)\n",
    "* OpenCV (features2d, objdetect, dnn, ml, 및 extra modules는 사용 불가)\n",
    "\n",
    "### 과제 제출물\n",
    "별도 표기된 항목을 제외하고는 아래 항목을 과제 종료시(16주차 수업시간 12/20일 13시까지) 제출한다. 이때 파일 형식 및 파일명 등의 규정은 가상대학 과제 출제 게시글을 참조한다.\n",
    "* 과제 계획서: \n",
    " - 어떤 유형의 과제를 수행할지, 어떤 방법론을 활용할지 조사하고 계획을 문서로 정리함 \n",
    " - 12주차 수업시간(11/22일 13시)까지, pdf 형식, font 크기 11, 3페이지 이내\n",
    " - 파일명 \"공학설계\\_기말과제-계획서\\_학번.pdf\" 예: 공학설계\\_기말과제-계획서\\_2018_1234.pdf\n",
    "* 과제 보고서: \n",
    " - 완료된 과제의 구현된/활용된 기법의 이론적인 개요, \n",
    " - 구현한/활용한 코드의 클래스/함수 등에 대해 API reference 형식 정리 (주요 알고리즘은 해당 함수 설명 내에 상세 내용 정리), \n",
    " - [정량적 실험 결과]-구현된 기법(들)의 테스트셋 정확도 수치(들 및 비교표), \n",
    " - [정성적 실험 결과]-구현된 기법에서 분류가 성공/실패하는 영상의 예시 및 원인에 대한 논의, 참고문헌 등을 포함함 \n",
    " - pdf 형식, font 크기 10, 8페이지 이내\n",
    " - 파일명 \"공학설계\\_기말과제-보고서\\_학번.pdf\" 예: 공학설계\\_기말과제-보고서\\_2018_1234.pdf\n",
    "* 과제 발표 동영상: \n",
    " - 과제 보고서의 내용을 요약 정리한 프리젠테이션 동영상 \n",
    " - mp4/mov/avi 등 형식, 3분 이내\n",
    " - 파일명 \"공학설계\\_기말과제-발표\\_학번.pdf\" 예: 공학설계\\_기말과제-발표\\_2018_1234.pdf \n",
    "* 과제 코드: \n",
    " - CIFAR-10 DB 폴더를 제외한 프로젝트 코드를 모두 압축한 파일 \n",
    " - zip 형식, 단일 파일, \n",
    " - 파일명 \"공학설계\\_기말과제-코드\\_학번.pdf\" 예: 공학설계\\_기말과제-코드\\_2018_1234.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CIFAR-10 DB Loading\n",
    "\n",
    "아래 CELL 1-2은 CIFAR DB를 다운로드 받고 본 프로그램에서 활용할 수 있도록 읽어오는 코드를 제시한다. \n",
    "코드를 실행시키면 DB를 다운로드 받아서 data와 참값 class 번호를 각각 변수 X와 y에 저장한다.\n",
    "이때 학습용 데이터와 테스트용 데이터를 각각 X_train 및 y_test과 X_test 및 y_test의 변수로 분할한다.\n",
    "\n",
    "** 혹시 아래 shell 스크립트가 실행되지 않을 경우 가상대학에 업로드한 데이터 파일을 다운받고 아래의 코드와 호환되도록 경로를 지정하시오. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'bash'은(는) 내부 또는 외부 명령, 실행할 수 있는 프로그램, 또는\n",
      "배치 파일이 아닙니다.\n"
     ]
    }
   ],
   "source": [
    "### CELL-1 ###\n",
    "# Download the CIFAR-10 DB to the current folder\n",
    "!bash get_datasets.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (50000, 32, 32, 3)\n",
      "Training labels shape:  (50000,)\n",
      "Test data shape:  (10000, 32, 32, 3)\n",
      "Test labels shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "### CELL-2 ###\n",
    "# Load the raw CIFAR-10 data\n",
    "from data_utils import load_CIFAR10\n",
    "\n",
    "cifar10_dir = 'cifar-10-batches-py'\n",
    "\n",
    "# Cleaning up variables to prevent loading data multiple times (which may cause memory issue)\n",
    "try:\n",
    "   del X_train, y_train\n",
    "   del X_test, y_test\n",
    "   print('Clear previously loaded data.')\n",
    "except:\n",
    "   pass\n",
    "\n",
    "X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "\n",
    "# As a sanity check, we print out the size of the training and test data.\n",
    "print('Training data shape: ', X_train.shape)\n",
    "print('Training labels shape: ', y_train.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 유형 1: Fixed classifier type (Linear SVM)\n",
    "\n",
    "feature 생성 함수를 별도의 셀 또는 별도의 .py 파일에 구현하고 아래 셀에서 호출하여 f_train 변수로 저장하고, 이를 이용하여 linear SVM을 학습하시오.\n",
    "이때 다양한 알고리즘을 실험하고 최고의 정확도 결과를 도출하는 알고리즘을 개발하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\dbs98\\AppData\\Local\\Temp/ipykernel_24912/1893513107.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m### Type-1 ###\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msvm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "### Type-1 ###\n",
    "from sklearn import svm\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "\n",
    "X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "clf = svm.SVC(kernel='linear')\n",
    "\n",
    "# YOUR FEATURE GENERATION CODE HERE #\n",
    "f_train = generate_features(X_train) # placeholder code, 자체 feature 생성 함수 호출 등으로 대체함\n",
    "# ...\n",
    "f_test = generate_features(X_test) # placeholder code, 자체 feature 생성 함수 호출 등으로 대체함\n",
    "# END YOUR CODE #\n",
    "\n",
    "\n",
    "### APPLY Linear SVM CLASSIFIER - 수정 가능하다고 명시한 코드 외에는 고정함 ###\n",
    "# import linear SVM class from scikit-learn\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# initialize linear SVM class object - LinearSVC 학습의 옵션 설정용 argument는 자유롭게 변경 가능함\n",
    "my_linsvm_cls = LinearSVC(max_iter=10000)\n",
    "\n",
    "# train linear SVM class object from X_train and y_train\n",
    "my_linsvm_cls.fit(f_train, y_train)\n",
    "\n",
    "# compute classification results for X_test and compute classification score by comparing with y_test\n",
    "acc = my_linsvm_cls.score(f_test,y_test)\n",
    "\n",
    "# check results - 이 부분 코드도 보고서에 작성하고자 하는 내용에 따라 자유롭게 수정함\n",
    "print(acc)\n",
    "# more code...\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 유형 2: Open Source type\n",
    "\n",
    "본 과제의 문제에 대한 기법을 조사하고, 성능이 좋은 기법을 찾아서 코드를 읽고 이해하고 주어진 데이터에 대해 실행하여 결과를 도출하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Type-2 ###\n",
    "\n",
    "# YOUR OPEN SOURCE CODE HERE #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "# Currently, memory growth needs to be the same across GPUs \n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True) \n",
    "            logical_gpus = tf.config.experimental.list_logical_devices('GPU') \n",
    "            print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\") \n",
    "    except RuntimeError as e: \n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "print(platform.python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
